{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrWfbkQXYMzynUHNW8tExO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-strasberg/LinguaLens/blob/liliana-data-preprocessing/data_collector_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C21w6d3TvYo2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "bc28e561-fd46-495d-f89b-61af7a6022bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'text_cleaner'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cf5d3f1d6e35>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m\"spanish\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"https://www.gutenberg.org/cache/epub/16172/pg16172.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     }\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mprocess_all_languages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgutenberg_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-cf5d3f1d6e35>\u001b[0m in \u001b[0;36mprocess_all_languages\u001b[0;34m(gutenberg_urls, output_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_all_languages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgutenberg_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'clean corpora'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# Download, clean, and save corpora from URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtext_cleaner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgutenberg_urls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'text_cleaner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_text(url=\"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\", filename=\"english.txt\", download_dir='corpora'):\n",
        "# Downloading a .txt file from Project Gurtenberg and saving it\n",
        "\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "    # To ensure the folder exists\n",
        "\n",
        "    response = requests.get(\"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\")\n",
        "    if response.status_code == 200:\n",
        "      path = os.path.join(download_dir, filename)\n",
        "      with open(path, 'w', encoding = 'utf-8') as f:\n",
        "        f.write(response.text)\n",
        "      print(f\"Downloaded and saved to {path}.\")\n",
        "    else:\n",
        "      print(\"Failed to download.\")\n",
        "\n",
        "def load_corpus(filepath):\n",
        "  # Load raw text from file\n",
        "  with open(filepath, 'r', encoding = 'utf-8') as f:\n",
        "    return f.read()\n",
        "\n",
        "def save_cleaned_text(language, cleaned_text, output_dir = 'clean_corpora'):\n",
        "  # Save clean text to new file\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "  out_path = os.path.join(output_dir, f\"{language}.txt\")\n",
        "  with open(out_path, 'w', encoding = 'utf-8') as f:\n",
        "    f.write(cleaned_text)\n",
        "\n",
        "def process_all_languages(gutenberg_urls, output_dir = 'clean corpora'):\n",
        "  # Download, clean, and save corpora from URLs\n",
        "  from text_cleaner import clean_text\n",
        "\n",
        "  for lang, url in gutenberg_urls.items():\n",
        "    filename = f\"{lang}.txt\"\n",
        "    download_text(url, filename, output_dir)\n",
        "    path = os.path.join(output_dir, filename)\n",
        "    raw_text = load_corpus(path)\n",
        "    cleaned = clean_text(raw_text)\n",
        "    save_cleaned_text(lang, cleaned, output_dir)\n",
        "    print(f\"Processed {lang}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gutenberg_urls = {\n",
        "        \"english\": \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\",\n",
        "        \"french\": \"https://www.gutenberg.org/cache/epub/17489/pg17489.txt\",\n",
        "        \"german\": \"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\",\n",
        "        \"spanish\": \"https://www.gutenberg.org/cache/epub/16172/pg16172.txt\"\n",
        "    }\n",
        "    process_all_languages(gutenberg_urls)"
      ]
    }
  ]
}